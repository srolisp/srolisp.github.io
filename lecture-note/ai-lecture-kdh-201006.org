#+title: 네이버, 구글 이미지 크롤링
#+subtitle: 6 weeks by kdh
#+date: <2020-10-06 Tue 18:00>
#+tags: python, bash, elisp, lisp, zoom
#+property: header-args:bash :results verbatim
#+property: header-args:elisp :exports both
#+property: header-args:ipython :session mglearn06 :tangle "mglearn201006.py" :exports both

#+author: srolisp

* TODO crawling
google 혹은 naver 에서 이미지 크롤링

검색어와 검색싸이트를 리스트로 입력, 각각의 검색싸이트에서 검색어마다 원하는 갯수 입력

저장경로(예시) google_images/2020-01-01/고양이/고양이10.jpg 

** 실행방법
#+begin_src ipython  :results output :export code
  # driver = set_webdriver(web_visual=True)
  # get_images(driver, ['고양이', '고양이 얼굴', '고양이 꼬리', '강아지'], ['naver', 'google'], 10)  # naver maximum items 1000
  # driver.close()
#+end_src

#+RESULTS:
: # Out[68]:

** 필요한 모듈 로드
#+begin_src ipython :results output :export code
  import os                       # 파일경로에 사용
  import time                     # 딜레이를 줄 필요가 있을 때 sleep 함수
  import datetime                 # 파일경로
  import ssl                      # 주소가 https 인 경우, urlretrieve로 이미지 다운받을 때 에러 처리

  from selenium import webdriver      # browser와 연동하는데 씀
  from urllib.parse import quote_plus # 한국어 검색 처리
  import urllib.request               # urlretrieve 함수 사용(이미지 다운로드)
  from selenium.webdriver.common.keys import Keys # PAGE_DOWN키를 전송할때 사용
  # exceptions 예외 처리모듈
  from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException,  ElementNotInteractableException, ElementClickInterceptedException, TimeoutException, InvalidSessionIdException
  from urllib.error import URLError, HTTPError
#+end_src

#+RESULTS:

** 무한 루프 방지 exception
#+begin_src ipython :results output :export code
  class TrialError(Exception):
      def __init__(self):
           super().__init__('TRIAL EXCESS')
#+end_src

#+RESULTS:

* Naver
** 네이버 제일 하단 이미지 더보기 클릭

1000개 넘어가면 사라지던데 NoSuchElementException 에러를 안뱉네.. 밑에 에러를 뱉는데 1001개까지 제공된다는 div가 나타나는지 체크후 처리

이미지 더보기 클릭이 정상적으로 수행되었으면 True 아니면 False
#+begin_src ipython :results output :export code
  def _no_more_img_click(drv):
      try:

          drv.find_element_by_css_selector('#_sau_imageTab > div.photowall._photoGridWrapper > div.more_img > a').click()
      except ElementNotInteractableException:
          if drv.find_element_by_css_selector('#_sau_imageTab > div.message_bottom._noMore'):
              print('ElementNotInteractableException - No More Image')
          else:
              print('ElementNotInteractableException')
          return False

      print('CLICK SUCCESS')
      return True
#+end_src

#+RESULTS:

** 여러개의 그리드박스내에 이미지 div들이 분할되어 있다. 

이미지 더보기가 눌러지면 그리드박스가 추가된다. 해당 인덱스의 그리드박스가 없을 경우 이미지 더보기 버튼을 눌러서 그리드박스가 추가되도록 한다.
#+begin_src ipython :results output :export code
  def _iidx_grid_box(drv, iidx):
      try:
          item = drv.find_element_by_css_selector('div.photowall._photoGridWrapper > div.photo_grid._box[data-box-idx="' + str(iidx) + '"]')

      except NoSuchElementException:
          print('No Grid Box(' + str(iidx) + ') created.')
          # drv.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)
          if _no_more_img_click(drv):
              return _iidx_grid_box(drv, iidx)
          else:
              return False
      except TrialError:
          print('TrialError')
          return False
      print('IIDX GRID BOX OPENED')
      return item
#+end_src

#+RESULTS:

** acc는 다운받은 총 이미지 수(이미지 파일명에 필요하다)
#+begin_src ipython :results output :export code
  def _retrieve2(drv, keyword, path, gbox, idx, acc):
      # 저장경로 
      if not (os.path.isdir(path)):
          os.makedirs(os.path.join(path))
      # 이미지 링크주소를 받아온다.
      img = gbox.find_element_by_css_selector('div > div:nth-child(' + str(idx) + ') > a > img._img').get_attribute('src')
      # 저장경로에 이미지 저장
      _retrieve(img, keyword, path, acc)
#+end_src

#+RESULTS:

** 원하는 갯수만큼 이미지를 받는다. True, 원하는 갯수(받은 갯수)
원하는 갯수만큼 못 받았을 경우 False, 받은 갯수

idx를 증가시키며 받다가 에러(NoSuchElementException)가
뜨면(그리드박스내 이미지는 다 받았으므로), 다음 그리드박스로부터
이미지를 받는다. 다음 그리드박스가 없어서 에러를 내면, 이미지 더보기를
클릭해서 그리드 박스가 추가되도록 시도한다.
#+begin_src ipython :results output :async t :export code
  def _inner_loop_naver_driver(drv, keyword, path, wanted, gbox, inner_idx=0, idx=1, acc=0):
      # 원하는 갯수만큼 받았으면 종료
      if acc == wanted:
          return True, acc

      # 그리드 안되고, 원하는 갯수만큼보다 적게 다운받은 경우 False
      if not gbox:
          return False, acc
      try:
          _retrieve2(drv, keyword, path, gbox, idx, acc)
      except NoSuchElementException: # 그리드박스내 이미지 idx 가 over
          return _inner_loop_naver_driver(drv, keyword, path, wanted, _iidx_grid_box(drv, inner_idx), inner_idx + 1, 1, acc)
      return _inner_loop_naver_driver(drv, keyword, path, wanted, gbox, inner_idx, idx + 1, acc + 1)


#+end_src

#+RESULTS:

* Google
** TODO 아래쪽은 구글부분인데 크게 다른부분이 없는 듯 하다. 나중에 정리.. 거의 비슷
#+begin_src ipython :results output :async t
  def _result_click(drv, idx):
      drv.find_element_by_css_selector('div.islrc > div:nth-child(' + str(idx) + ') > a.wXeWr.islib.nfEiy.mM5pbd').click()

  def _inner_loop_google_driver2(drv, keyword, path, wanted, idx=1, acc=0):
      if acc == wanted:
          return True, acc
      try:
          _result_click(drv, idx)
      # TODO 1000 over
      except NoSuchElementException: 
          print('NOSUCHE: ', drv.find_element_by_css_selector('#islrg > div.islrc > div:nth-child(25) > div > div.a3Wc3.O8VmIc > div').text, idx)
          return _inner_loop_google_driver2(drv, keyword, path, wanted, idx+1, acc)

      if _retrieve(drv.find_element_by_css_selector('#Sva75c > div > div > div.pxAole > div.tvh9oe.BIB1wf > c-wiz > div.OUZ5W > div.zjoqD > div > div.v4dQwb > a > img.n3VNCb').get_attribute('src'), keyword, path, idx):
          return _inner_loop_google_driver2(drv, keyword, path, wanted, idx+1, acc+1)
      return _inner_loop_google_driver2(drv, keyword, path, wanted, idx+1, acc)

#+end_src

#+RESULTS:

* 공통부분
#+begin_src ipython :results output :export code
  def _loop_naver_driver(drv, keyword, path, wanted):
      time.sleep(2)               # 초기로딩 지연이 종종 있어서 2초가 sleep후 진행
      return _inner_loop_naver_driver(drv, keyword, path, wanted, _iidx_grid_box(drv, 0))

  def _get_naver_items(drv, url, keyword, host, wanted):
      drv.get(url + quote_plus(keyword))
      path = host + '_images/' + str(datetime.date.today()) + '/' + keyword

      return _loop_naver_driver(drv, keyword, path, wanted)

  def loop_google_driver(drv, keyword, path, wanted):
       time.sleep(2)
       return _inner_loop_google_driver2(drv, keyword, path, wanted)

  def _get_google_items(drv, url, keyword, host, wanted):
      drv.get(url)
      drv.find_element_by_css_selector('div.a4bIc > input').send_keys(keyword + '\n')

      path = host + '_images/' + str(datetime.date.today()) + '/' + keyword
      new_items = loop_google_driver(drv, keyword, path, wanted)
      return new_items

  def _retrieve(img, keyword, path, idx, trial=0, max_trial=50):
      if not (os.path.isdir(path)):
          os.makedirs(os.path.join(path))
      try:
          if trial > max_trial:
               raise TrialError
          urllib.request.urlretrieve(img, path + '/' + keyword + str(idx) + '.jpg')
      except URLError:
          # URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local
          print('ERROR URLError in _retrieve', trial)
          ssl._create_default_https_context = ssl._create_unverified_context
          trial += 1
          _retrieve(img, keyword, path, idx, trial)
      except HTTPError:
           print('ERROR HTTPError in _retrieve', img, trial)
           trial += 1
           _retrieve(img, keyword, path, idx, trial)
      except TrialError:
          print('TrialError - Failed', img)
          return False
      return True

  def _get_images(drv, keyword, host, n_items, 
                  d_servs={'naver' : ['https://search.naver.com/search.naver?where=image&sm=tab_jum&query=', _get_naver_items],
                           'google' : ['https://www.google.co.kr/imghp?hl=ko&tab=wi&authuser=0&ogbl', _get_google_items]}):
      url = d_servs[host][0]
      fn = d_servs[host][1]
      print(fn(drv, url, keyword, host, n_items))

  def _get_images_by_hosts(drv, keyword, hosts, n_items):
       if hosts == []:
           print('HOSTS OK')
       else:
           _get_images(drv, keyword, hosts[0], n_items)
           _get_images_by_hosts(drv, keyword, hosts[1:], n_items)

  def get_images(drv, keywords, hosts, n_items):
      if keywords == []:
          print ('KEYWORDS OK')
      else:
          _get_images_by_hosts(drv, keywords[0], hosts, n_items)
          get_images(drv, keywords[1:], hosts, n_items)
#+end_src

#+RESULTS:

* web_driver가 설정 안하면 chromdriver 사용, web_visual 설정 안되면 웹브라우저를 열지않고 실행
#+begin_src ipython :results output :export code
  def set_webdriver(web_driver=None, web_visual=None):
      if web_driver is None:
          chrome_options = webdriver.ChromeOptions()
          if web_visual is None:
              chrome_options.add_argument('--headless')
              chrome_options.add_argument('--no-sandbox')
              chrome_options.add_argument('--disable-dev-shm-usage')
          driver = webdriver.Chrome('/Users/sroh/Downloads/chromedriver', options=chrome_options)
      else:
          driver = web_driver

      return driver
#+end_src

#+RESULTS:

* TODO 개선시켜볼 부분

** 구글같은 경우, 이미지 중간중간 연관검색어를 넣어놨다. 이 연관 검색어를 참고해서 관련 이미지를 자동으로 다운시켜봐도 좋을 것 같다.

** Code 정리

** 1000개 이상 입력 받았을 때 예외처리(Google) 

** 다운 받은 Image 에 문제가 있는 경우 처리

* TEST
#+begin_src ipython :results output :async t
  driver = set_webdriver(web_visual=True)
  get_images(driver, ['hardhat'], ['google'], 1001)
  driver.close
#+end_src

#+RESULTS:
: 0 - 8da97e48-8fff-4cb2-8310-18ff143c5ad6
