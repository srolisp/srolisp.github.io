#    -*- mode: org -*-


Archived entries from file /Users/sroh/pg/2020/python/uiap/lecture-note/ai-lecture-lsk-200917<-200927-logistic-reggression.org


* Implements
  :PROPERTIES:
  :ARCHIVE_TIME: 2020-10-04 Sun 17:03
  :ARCHIVE_FILE: ~/pg/2020/python/uiap/lecture-note/ai-lecture-lsk-200917<-200927-logistic-reggression.org
  :ARCHIVE_CATEGORY: ai-lecture-lsk-200917<-200927-logistic-reggression
  :END:
#+begin_src ipython :results output 
    import numpy as np
    from numpy.linalg import inv
    class LogisticRegression:

        def __init__(self, lr=0.001, n_iters=1000):
            self.lr = lr
            self.n_iters = n_iters
            self.weights = None
            self.bias = None

        def fit(self, X, y):
            # # init parameters
            n_samples, n_features = X.shape
            self.weights = np.zeros(X.shape[1])
            # self._print_debug('X', X)
            # self._print_debug('y', y)

            for _ in range(self.n_iters):
              # wx = np.dot(X, self.weights)
              # self._print_debug('wx', wx)
              #self._print_debug('weights', self.weights)

              a = self._sigmoid(np.dot(X, self.weights))
              # self._print_debug('a', a)
              one_a = np.array([1-a_i for a_i in a])
              B = np.diag(a * one_a)
              # self._print_debug('B', B)
              dldw = np.dot((a - y).T, X)
              # self._print_debug('dldw', dldw)

              d2ldw2 = np.dot(np.dot(X.T, B), X)
              # self._print_debug('d2ldw2', d2ldw2)
              inv_d2ldw2 = inv(d2ldw2)
              # self._print_debug('inv_d2ldw2', inv(d2ldw2)) 
              self.weights -= np.dot(inv_d2ldw2, dldw)

        def predict(self, X):
            y_predicted = self._sigmoid(np.dot(X, self.weights))
            y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]
            return y_predicted_cls

        def _sigmoid(self, a):
             return 1 / (1 + np.exp(-a))

        def _print_debug(self, str, X):
             print(str + '\n', X.shape)
             print(X)



    from sklearn.model_selection import train_test_split
    from sklearn import datasets
    import matplotlib.pyplot as plt

    bc = datasets.load_breast_cancer()
    X, y = bc.data[:,0:2], bc.target
    # print(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)

    def accuracy(y_true, y_pred):
        accuracy = np.sum(y_true == y_pred) / len(y_true)
        return accuracy
    r = LogisticRegression()

    r.fit(X_train, y_train)
    predictions = r.predict(X_test)

    print("LR classification accuracy:", accuracy(y_test, predictions))
    # test = np.arange(9).reshape(3,3)
    # test = np.array([[1,1,1],[0,2,5],[2,5,-1]])
    # print(np.linalg.inv(test))
    # a = np.array([[1,1,1],[0,2,5],[2,5,-1]])


  # print( np.linalg.inv(a) )
  # ainv = np.linalg.inv(a) 
#+end_src

#+RESULTS:
: LR classification accuracy: 0.6929824561403509

#+begin_src ipython :results output
print(np.random.random_integers(0,1, 20))
#+end_src

#+RESULTS:
: [0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0]
: /Users/sroh/.pyenv/versions/anaconda3-5.3.1/envs/uiap/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead
:   """Entry point for launching an IPython kernel.
